---
title: "ad-col_prelim"
output: html_document
author: Jhon Montero & Zack Arno
date: "`r Sys.Date()`"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  comment = "#>"
)
```

```{css, echo=FALSE}
.scroll-500 {
  max-height: 500px;
  overflow-y: auto;
  background-color: inherit;
}

.scroll-200 {
  max-height: 200px;
  overflow-y: auto;
  background-color: inherit;
}

```

```{css, echo=FALSE}
/* Para los scripts*/
pre {
max-height: 250px;
overflow-y: auto;
}

/* Para que se mueva en x guardando las proporciones*/
pre code {
  word-wrap: normal;
  white-space: pre;
}

/* Para las salidas generadas
pre[class] {
max-height: 200px;
}*/

```

## Load data, libraris and survey

Libraries and any parameterization

```{r setup,  warning=FALSE, message = FALSE}
library(GeoMSNA2022)
library(readxl)
library(sf)
library(tidyverse)
library(srvyr)
library(leaflet)
library(kableExtra)
library(shiny)

devtools::load_all()
country_code="col"

# you can add more vars here 
vars_1_5_factor <-  c("lsg_score_sa", "lsg_score_wash", "msni")

#' fct_expand_relevel
#' @description for some reason fct_expand does not also relevel according to argument input order
#' therefore have made a wrapper to expand and then relevel
#' @param x  variable
#' @param levels factor levels to expand to and relevel according to input order
#'
#' @return vector releveled
fct_expand_relevel <-  function(x,levels){
  x_fct <- as_factor(x)
  x_expanded <-forcats::fct_expand(x_fct, levels)
  x_releveled <-  forcats::fct_relevel(x_expanded,levels)
  return(x_releveled)
}

```

data and survey

```{r}
data <- read_excel(file.path(input_dir(country_code="col"),"REACH_COL_LSGMSNI_08112022.xlsx"),
                   guess_max = min(60000, n_max = NULL), sheet = "Sheet1")

ks <- read_excel(file.path(input_dir(country_code="col"),"MSNA-6ta ronda- Formulario final_v7.xlsx"), 
                     sheet = "survey",
                     guess_max = min(60000, n_max = NULL))

kc <- read_excel(file.path(input_dir(country_code="col"),
                                "MSNA-6ta ronda- Formulario final_v7.xlsx"),
                      sheet = "choices",
                      guess_max = min(60000, n_max = NULL))

gee <- readRDS(file.path(input_dir(country_code="col"),
                         "20221026_col_rs_indicators_with_uuid.rds"))
```

# Limpieza de datos

```{r}
# Ver valores de NA en la base de datos
x <- as.data.frame(colSums(is.na(gee)))
x <- x |> mutate(obser = 5485) |> 
  mutate(perc_NA = `colSums(is.na(gee))` / obser * 100)

x |> arrange(desc(perc_NA))

gee <- gee |> select(-rs_col_lc_2018.nivel_6, -rs_col_lc_2018.nivel_5, -rs_col_lc_2018.nivel_4, 
                      -rs_NO2_column_number_density_mean, -rs_SO2_column_number_density_15km_mean, 
                      -rs_SO2_column_number_density_amf_mean, -rs_SO2_column_number_density_mean, 
                      -rs_cloud_fraction_mean, -rs_cloud_fraction_mean_1, 
                      -rs_tropospheric_NO2_column_number_density_mean, -rs_Npp_2020, -rs_Npp_2021, 
                      -rs_Npp_Z_2020, -rs_Npp_Z_2021, -rs_Npp_mean_2020, -rs_Npp_mean_2021, 
                      -rs_Npp_median_2020, -rs_Npp_median_2021, -rs_Npp_pct_median_2020, -rs_Npp_pct_median_2021)
```

```{r}
shp <- st_read(file.path(input_dir(country_code="col"),
                         "shp/REACH_COL_EncuestasMSNA.shp"))

ame <- st_read(file.path(input_dir(country_code="col"),
                         "shp/REACH_COL_SusceptibleInundacion.shp"))

leaflet(options = leafletOptions(attributionControl=FALSE, )) |>
  addMapPane(name = "polygons", zIndex = 410) |>                                  # Agregar panel para poligonos
  addMapPane(name = "puntos", zIndex = 420) |>  
  addMapPane(name = "label", zIndex = 430) |> 
  addPolygons(data = ame, fill = TRUE, fillOpacity = 0.7, fillColor = "#EE5859",  # Caracteristicas del poligono ame
              stroke = TRUE, color = "#F3BEBD", weight = 0.3, opacity = 1,
              highlight = highlightOptions(                                       # Si se quiere resaltar cuando se pase por encima del poligono
                weight = 5,
                color = "#666666",
                fillOpacity = 0.75,
                bringToFront = TRUE
              ), 
              options = leafletOptions(pane = "polygons")) |> 
  addLegend(
    "bottomright", colors = "#EE5859", labels = unique(ame$SUSCEPTIBL),           # Se agrega la leyenda manual
    title = "Tipo de amenaza:", opacity = 1) |> 
  addCircles(data = shp, fill = TRUE, fillOpacity = 0.7, fillColor = "#58EEED", weight = 1,
             stroke = TRUE, color = "red", opacity = 1)


```

Validacion de datos para hacer join

```{r}
# Validar que no hayan errores de geometria en los shp
#st_is_valid(ame)
#st_is_valid(shp)

# Si hay errores validarlos para que se pueda trabajar con los datos
ame <- st_make_valid(ame)

# Spatial Join
inundacion <- st_join(shp, ame, left = TRUE)

# Join atribute
data2 <- data %>% left_join(inundacion, by = c("uuid" = "F_uuid"))
data2 <- data2 %>% select(-geometry)

data <- data2 %>% left_join(gee, by = "uuid")

data_w_rs <- data %>% mutate(inundacion = case_when(SUSCEPTIBL == "Inundación" ~ "Amenaza por inundación",
                                               TRUE ~ "No hay amenaza por inundación"))

rm(ame, data2, inundacion, shp, x)
```

some tools I've made that I find handy for working with kobo data `{xlsf}`

```{r}
qdf <- xlsf::xlsf_load(survey = ks, choices = kc, data_main = data_w_rs, sm_sep = "/")


# this just refactors dat according to kobo tool - it's nice pre processing step before aggregating
# so levels don't get dropped
qdf$data_main <- xlsf::xlsf_relevel(qdf$data_main, xlsf = qdf)

qdf$data_main <- qdf$data_main |> 
  mutate(
    across(
      .cols = all_of(vars_1_5_factor),
      .fns = ~fct_expand_relevel(x=.x, levels = c("1","2","3","4","5"))
  )
  )

```

create survey object for weighted calcs

```{r}
dfsvy <-  srvyr::as_survey(qdf$data_main, weight=pesos)
```

organizar la información para generar las tablas

```{r}
#sort(names(gee))
gee2 <- gee %>% select(-uuid)
variables <- c(names(gee2), "inundacion", "SUSCEPTIBL")

sectores <- c("lsg_score_pro", "proteccion", "lsg_score_sa", "segaliment",
              "lsg_score_shelter", "alojamiento", "lsg_score_wash", "aguasanea",
              "lsg_score_edu", "educacion", "lsg_score_salud", "saludlsg",
              "lsg_score_mdv", "mediosvida", "msni", "msni_lsg_cate")
```

## ANÁLISIS ESPACIAL

## 1. Proporciones y medianas {.tabset .tabset-fade .tabset-pills}

Se calcularon los porcentajes para las variables categoricas y la media, mediana, 1er quartil y 3er quartil

### Total: Categoricas

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
for (i in variables) {
  if (is.character(dfsvy$variables[[i]])) {
    for (j in sectores) {
      tabla <- dfsvy |> filter(!is.na(!!sym(i))) |>  group_by(!!sym(j), !!sym(i)) |>                       # filtro si hay NA y agrupar por las variables categoricas
        summarise(n = n(),                                                                                 # manera de calcular el numero de datos
                  porcentaje = survey_mean( proportion = T, na.rm = F, vartype = "ci", level = 0.95)) |>   # manera de calcular el ponderado con CI de 0.95
        pivot_wider(id_cols = i,#i                                                                         # hacer un pivot donde se deja la columna de variables
          names_from = j,#j                                                                                # la columna que se va a dividir en varias sera el de sectores
          values_from = c(n, porcentaje, porcentaje_low, porcentaje_upp))                                  # organizando las variables de n, porcentaje, etc..
      
      tabla <- if ("porcentaje_NA" %in% names(tabla)) {                                                    # eliminar las columns con NA
        tabla |> select(-porcentaje_NA, -porcentaje_low_NA, -porcentaje_upp_NA)
      }else{
        tabla
      }
      
      kable(tabla, format = "pipe", caption = paste(i, " VS ", j, sep = "")) |> print()                    # Generar la salida de las tablas
    }
  }
}
```

### Total: Numericas

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
for (i in variables) {
  if (is.numeric(dfsvy$variables[[i]])) {
    for (j in sectores) {
      
      tabla <- dfsvy |> filter(!is.na(!!sym(j))) |>  group_by(!!sym(j)) |>                                 # filtro si hay NA y agrupar por la variable categorica (sectores)
        summarise(n = n(),
                  mean = survey_mean(!!sym(i), na.rm = F, vartype = "ci",level = 0.95),                    # manera de calcular el promedio con CI de 0.95
                  median = survey_median(!!sym(i), na.rm = F, vartype = "ci", level = 0.95),               # manera de calcular la mediana con CI de 0.95
                  quan = survey_quantile(!!sym(i), c(0.25, 0.75), vartype = "ci", level = 0.95))           # manera de calcular el 1er quan y 3er quan con CI de 0.95
      
      kable(tabla, format = "pipe", caption = paste(i, " VS ", j, sep = "")) |> print()                    # Generar la salida de las tablas
    }
  }
}
```

### OCHA: Categoricas

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
for (i in variables) {
  if (is.character(dfsvy$variables[[i]])) {
    for (j in sectores) {
      tabla <- dfsvy |> filter(pop_group %in% c("población de acogida", "PDI")) |> 
        filter(!is.na(!!sym(i))) |>  group_by(!!sym(j), !!sym(i)) |>
        summarise(n = n(), 
                  porcentaje = survey_mean( proportion = T, na.rm = F, vartype = "ci")) |>
        pivot_wider(id_cols = i,#i
          names_from = j,#j
          values_from = c(n, porcentaje, porcentaje_low, porcentaje_upp))
      
      tabla <- if ("porcentaje_NA" %in% names(tabla)) {
        tabla |> select(-porcentaje_NA, -porcentaje_low_NA, -porcentaje_upp_NA)
      }else{
        tabla
      }
      
      kable(tabla, format = "pipe", caption = paste(i, " VS ", j, sep = "")) |> print()
    }
  }
}
```

### OCHA: Numericas

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
for (i in variables) {
  if (is.numeric(dfsvy$variables[[i]])) {
    for (j in sectores) {
      
      
      tabla <- dfsvy |> filter(pop_group %in% c("población de acogida", "PDI")) |> 
        filter(!is.na(!!sym(j))) |>  group_by(!!sym(j)) |>                                                 # filtro si hay NA y agrupar por la variable categorica (sectores)
        summarise(n = n(),
                  mean = survey_mean(!!sym(i), na.rm = F, vartype = "ci",level = 0.95),                    # manera de calcular el promedio con CI de 0.95
                  median = survey_median(!!sym(i), na.rm = F, vartype = "ci", level = 0.95),               # manera de calcular la mediana con CI de 0.95
                  quan = survey_quantile(!!sym(i), c(0.25, 0.75), vartype = "ci", level = 0.95))           # manera de calcular el 1er quan y 3er quan con CI de 0.95
      
      kable(tabla, format = "pipe", caption = paste(i, " VS ", j, sep = "")) |> print()                    # Generar la salida de las tablas
    }
  }
}
```

### GIFMM: Categoricas

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
for (i in variables) {
  if (is.character(dfsvy$variables[[i]])) {
    for (j in sectores) {
      tabla <- dfsvy |> filter(!(pop_group %in% c("población de acogida", "PDI"))) |> 
        filter(!is.na(!!sym(i))) |>  group_by(!!sym(j), !!sym(i)) |>
        summarise(n = n(), 
                  porcentaje = survey_mean( proportion = T, na.rm = F, vartype = "ci")) |>
        pivot_wider(id_cols = i,#i
          names_from = j,#j
          values_from = c(n, porcentaje, porcentaje_low, porcentaje_upp))
      
      tabla <- if ("porcentaje_NA" %in% names(tabla)) {
        tabla |> select(-porcentaje_NA, -porcentaje_low_NA, -porcentaje_upp_NA)
      }else{
        tabla
      }
      
      kable(tabla, format = "pipe", caption = paste(i, " VS ", j, sep = "")) |> print()
    }
  }
}
```

### GIFMM: Numericas

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
for (i in variables) {
  if (is.numeric(dfsvy$variables[[i]])) {
    for (j in sectores) {
      
      
      tabla <- dfsvy |> filter(!(pop_group %in% c("población de acogida", "PDI"))) |> 
        filter(!is.na(!!sym(j))) |>  group_by(!!sym(j)) |>                                                 # filtro si hay NA y agrupar por la variable categorica (sectores)
        summarise(n = n(),
                  mean = survey_mean(!!sym(i), na.rm = F, vartype = "ci",level = 0.95),                    # manera de calcular el promedio con CI de 0.95
                  median = survey_median(!!sym(i), na.rm = F, vartype = "ci", level = 0.95),               # manera de calcular la mediana con CI de 0.95
                  quan = survey_quantile(!!sym(i), c(0.25, 0.75), vartype = "ci", level = 0.95))           # manera de calcular el 1er quan y 3er quan con CI de 0.95
      
      kable(tabla, format = "pipe", caption = paste(i, " VS ", j, sep = "")) |> print()                    # Generar la salida de las tablas
    }
  }
}
```

##  {.unnumbered}

## 2. Correlaciones {.tabset .tabset-fade .tabset-pills}

Se calcularon las correlaciones para las variables numericas en los tres casos de evaluacion

### Total: Sin pesos

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
# Variables de predictoras
gee2 <- gee %>% select(-uuid)
variables <- names(gee2)

for (i in sectores) {

  # Variables de gee
  #class(dfsvy$variables[[i]]) <- as.numeric(dfsvy$variables[[i]])
  modelos <- dfsvy$variables[,names(dfsvy$variables) %in% c(variables, i)]
  modelos[[i]] <- as.numeric(modelos[[i]])
  modelos<- modelos %>% select(is.numeric, i)
  names(modelos)

  best_pred <- as.data.frame(modelos |> 
    select(-i) |> 
    map_dbl(cor, y = modelos[[i]], use = "pairwise.complete.obs", ) |> 
    abs() |> 
    sort(decreasing = TRUE) |> 
    (\(x) (x[1:5]))()) |> rownames_to_column()
  
  names(best_pred) <- c("rs_variables", i)
  best_pred <- best_pred |> mutate(!!sym(i) := round(!!sym(i) * 100, 4))
  names(best_pred) <- c("rs_variables", paste(i, "(%)"))
  

  kable(best_pred, format = "pipe", caption = paste("Mejores correlaciones con: ", i, sep = "")) |> print()
}
```

### Total: Con pesos

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}

for (i in sectores) {
  out <- jtools::svycor(~as.numeric(dfsvy$variables[[i]]) + rs_rx10d_30d_may + rs_rx3d_30d_may + rs_rx5d_30d_may + rs_rx10d_60d_may + rs_rx3d_60d_may + rs_rx5d_60d_may + rs_rx10d_90d_may + rs_rx3d_90d_may + rs_rx5d_90d_may + rs_NDVI_Mar2022 + rs_NDVI_pct_median_Mar2022 + rs_NDVI_z_score_Mar2022 + rs_VCI_Mar2022 + rs_NDVI_Apr2022 + rs_NDVI_pct_median_Apr2022 + rs_NDVI_z_score_Apr2022 + rs_VCI_Apr2022 + rs_NDVI_May2022 + rs_NDVI_pct_median_May2022 + rs_NDVI_z_score_May2022 + rs_VCI_May2022 + rs_May_spi12 + rs_May_spi1 + rs_May_spi3 + rs_May_spi6 + rs_May_spi9 + rs_dist_coast + rs_city_accessibility2015 + rs_healthcare_accessbility_walking_only2019 + rs_healthcare_accessibility2019 + rs_col_climate_risk.valor_ries + rs_col_climate_risk.riesgo_cc + rs_col_climate_risk.vn_vs_am, design = dfsvy, na.rm = T)

  
  out <- as.data.frame(out$cors)
  out <- abs(out[1]) |> arrange(-out[1]) |> rownames_to_column() |> 
    (\(x)(x[-1,]))()
  
  names(out) <- c("rs_variables", i)
  out <- out |> mutate(!!sym(i) := round(!!sym(i) * 100, 4))
  names(out) <- c("rs_variables", paste(i, "(%)"))

  kable(head(out), format = "pipe", caption = paste("Mejores correlaciones con: ", i, sep = "")) |> print()
}
```

### OCHA: Sin pesos

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
# Variables de predictoras
gee2 <- gee %>% select(-uuid)
variables <- names(gee2)

for (i in sectores) {

  # Variables de gee
  #class(dfsvy$variables[[i]]) <- as.numeric(dfsvy$variables[[i]])
  modelos <- dfsvy |> filter((pop_group %in% c("población de acogida", "PDI"))) |> 
    (\(X)(X$variables[,names(X$variables) %in% c(variables, i)]))()
  
  modelos[[i]] <- as.numeric(modelos[[i]])
  modelos<- modelos %>% select(is.numeric, i)
  names(modelos)

  best_pred <- as.data.frame(modelos |> 
    select(-i) |> 
    map_dbl(cor, y = modelos[[i]], use = "pairwise.complete.obs", ) |> 
    abs() |> 
    sort(decreasing = TRUE) |> 
    (\(x) (x[1:5]))()) |> rownames_to_column()
  
  names(best_pred) <- c("rs_variables", i)
  best_pred <- best_pred |> mutate(!!sym(i) := round(!!sym(i) * 100, 4))
  names(best_pred) <- c("rs_variables", paste(i, "(%)"))

  kable(best_pred, format = "pipe", caption = paste("Mejores correlaciones con: ", i, sep = "")) |> print()
}
```

### OCHA: Con pesos

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}

for (i in sectores) {
  out <- dfsvy |> filter((pop_group %in% c("población de acogida", "PDI")))
  
  out <- jtools::svycor(~as.numeric(out$variables[[i]]) + rs_rx10d_30d_may + rs_rx3d_30d_may + rs_rx5d_30d_may + rs_rx10d_60d_may + rs_rx3d_60d_may + rs_rx5d_60d_may + rs_rx10d_90d_may + rs_rx3d_90d_may + rs_rx5d_90d_may + rs_NDVI_Mar2022 + rs_NDVI_pct_median_Mar2022 + rs_NDVI_z_score_Mar2022 + rs_VCI_Mar2022 + rs_NDVI_Apr2022 + rs_NDVI_pct_median_Apr2022 + rs_NDVI_z_score_Apr2022 + rs_VCI_Apr2022 + rs_NDVI_May2022 + rs_NDVI_pct_median_May2022 + rs_NDVI_z_score_May2022 + rs_VCI_May2022 + rs_May_spi12 + rs_May_spi1 + rs_May_spi3 + rs_May_spi6 + rs_May_spi9 + rs_dist_coast + rs_city_accessibility2015 + rs_healthcare_accessbility_walking_only2019 + rs_healthcare_accessibility2019 + rs_col_climate_risk.valor_ries + rs_col_climate_risk.riesgo_cc + rs_col_climate_risk.vn_vs_am, design = out, na.rm = T)

  
  out <- as.data.frame(out$cors)
  out <- abs(out[1]) |> arrange(-out[1]) |> rownames_to_column() |> 
    (\(x)(x[-1,]))()
  
  names(out) <- c("rs_variables", i)
  out <- out |> mutate(!!sym(i) := round(!!sym(i) * 100, 4))
  names(out) <- c("rs_variables", paste(i, "(%)")) 


  kable(head(out), format = "pipe", caption = paste("Mejores correlaciones con: ", i, sep = "")) |> print()
}
```

### GIFMM: Sin pesos

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}
# Variables de predictoras
gee2 <- gee %>% select(-uuid)
variables <- names(gee2)

for (i in sectores) {

  # Variables de gee
  #class(dfsvy$variables[[i]]) <- as.numeric(dfsvy$variables[[i]])
  modelos <- dfsvy |> filter(!(pop_group %in% c("población de acogida", "PDI"))) |> 
    (\(X)(X$variables[,names(X$variables) %in% c(variables, i)]))()
  
  modelos[[i]] <- as.numeric(modelos[[i]])
  modelos<- modelos %>% select(is.numeric, i)
  names(modelos)

  best_pred <- as.data.frame(modelos |> 
    select(-i) |> 
    map_dbl(cor, y = modelos[[i]], use = "pairwise.complete.obs", ) |> 
    abs() |> 
    sort(decreasing = TRUE) |> 
    (\(x) (x[1:5]))())|> rownames_to_column()
  
  names(best_pred) <- c("rs_variables", i)
  best_pred <- best_pred |> mutate(!!sym(i) := round(!!sym(i) * 100, 4))
  names(best_pred) <- c("rs_variables", paste(i, "(%)"))

  kable(best_pred, format = "pipe", caption = paste("Mejores correlaciones con: ", i, sep = "")) |> print()
}
```

### GIFMM: Con pesos

```{r message=FALSE, warning=FALSE, class.output="scroll-500"}

for (i in sectores) {
  out <- dfsvy |> filter(!(pop_group %in% c("población de acogida", "PDI")))
  
  out <- jtools::svycor(~as.numeric(out$variables[[i]]) + rs_rx10d_30d_may + rs_rx3d_30d_may + rs_rx5d_30d_may + rs_rx10d_60d_may + rs_rx3d_60d_may + rs_rx5d_60d_may + rs_rx10d_90d_may + rs_rx3d_90d_may + rs_rx5d_90d_may + rs_NDVI_Mar2022 + rs_NDVI_pct_median_Mar2022 + rs_NDVI_z_score_Mar2022 + rs_VCI_Mar2022 + rs_NDVI_Apr2022 + rs_NDVI_pct_median_Apr2022 + rs_NDVI_z_score_Apr2022 + rs_VCI_Apr2022 + rs_NDVI_May2022 + rs_NDVI_pct_median_May2022 + rs_NDVI_z_score_May2022 + rs_VCI_May2022 + rs_May_spi12 + rs_May_spi1 + rs_May_spi3 + rs_May_spi6 + rs_May_spi9 + rs_dist_coast + rs_city_accessibility2015 + rs_healthcare_accessbility_walking_only2019 + rs_healthcare_accessibility2019 + rs_col_climate_risk.valor_ries + rs_col_climate_risk.riesgo_cc + rs_col_climate_risk.vn_vs_am, design = out, na.rm = T)

  
  out <- as.data.frame(out$cors)
  out <- abs(out[1]) |> arrange(-out[1]) |> rownames_to_column() |> 
    (\(x)(x[-1,]))()
  
  names(out) <- c("rs_variables", i)
  out <- out |> mutate(!!sym(i) := round(!!sym(i) * 100, 4))
  names(out) <- c("rs_variables", paste(i, "(%)"))


  kable(head(out), format = "pipe", caption = paste("Mejores correlaciones con: ", i, sep = "")) |> print()
}
```

##  {.unnumbered}

## Analisis exploratorio

### COMPLETO

Cuando se realizaron las correlaciones para todo el conjunto de datos hay una fuerte influencia de los datos de GIFMM lo que baja las correlaciones entre los LSG de algunos sectores con las variables de RS, siendo el sector con mayor correlacion el de WASH seguido del MSNI.

## WASH {.tabset .tabset-fade .tabset-pills}

la variable Lsg_score_wash tuvo correlaciones mayores del 20% con las variables de remote sensing rs_healthcare_accessbility_walking_only2019, rs_healthcare_accessibility2019m, rs_NDVI_May2022 y rs_city_accessibility2015; En todos los casos se ve una correlacion positiva.

### rs_healthcare_accessbility_walking_only2019

Travel time to the nearest hospital or clinic using non-motorized transport (min). correlacion de 32.85%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_wash)) %>% 
           group_by(lsg_score_wash) %>% 
  summarise(distance_mean = survey_mean(rs_healthcare_accessbility_walking_only2019, na.rm = T, "ci")) %>% 
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash)) |> 
      group_by(lsg_score_wash) |> 
  count()) |> 
  ggplot(aes(x = lsg_score_wash, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin= `distance_mean_low`,
        ymax= `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH", y = "Average travel time to the nearest hospital (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 220, fill = NULL)) + 
  theme_bw()
```

### rs_healthcare_accessibility2019

Travel time to the nearest hospital or clinic (min). Correlacion de 26.92%.

```{r}

dfsvy |> 
  filter(!is.na(lsg_score_wash)) %>% 
           group_by(lsg_score_wash) %>% 
  summarise(distance_mean = survey_mean(rs_healthcare_accessibility2019, na.rm = T, "ci")) %>% 
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash)) |> 
      group_by(lsg_score_wash) |> 
  count()) |> 
  ggplot(aes(x = lsg_score_wash, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin= `distance_mean_low`,
        ymax= `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH", y = "Average travel time to the nearest hospital (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 50, fill = NULL)) + 
  theme_bw()
```

### rs_NDVI_May2022

NDVI May 2022, The product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. Correlacion de 25.44%.

```{r}

dfsvy |> 
  filter(!is.na(lsg_score_wash)) %>% 
           group_by(lsg_score_wash) %>% 
  summarise(distance_mean = survey_mean(rs_NDVI_May2022, na.rm = T, "ci")) %>% 
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash)) |> 
      group_by(lsg_score_wash) |> 
  count()) |> 
  ggplot(aes(x = lsg_score_wash, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin= `distance_mean_low`,
        ymax= `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH", y = "Average NDVI May")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 0.7, fill = NULL)) + 
  theme_bw()
```

### rs_city_accessibility2015

Travel time to the nearest densely-populated area (min). Correlacion de 21.37%.

```{r}

dfsvy |> 
  filter(!is.na(lsg_score_wash)) %>% 
           group_by(lsg_score_wash) %>% 
  summarise(distance_mean = survey_mean(rs_city_accessibility2015, na.rm = T, "ci")) %>% 
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash)) |> 
      group_by(lsg_score_wash) |> 
  count()) |> 
  ggplot(aes(x = lsg_score_wash, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin= `distance_mean_low`,
        ymax= `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH", y = "Average travel time (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 100, fill = NULL)) + 
  theme_bw()
```

##  {.unnumbered}

## MSNI {.tabset .tabset-fade .tabset-pills}

la variable msni tuvo correlaciones mayores del 20% con las variables de remote sensing rs_healthcare_accessbility_walking_only2019 y rs_healthcare_accessibility2019

### rs_healthcare_accessbility_walking_only2019

Correlacion de 24.02%.

```{r}

dfsvy %>% group_by(msni) %>% 
  summarise(distance_mean = survey_mean(rs_healthcare_accessbility_walking_only2019, na.rm = T , "ci")) %>% 
  left_join(
    #get raw counts
    dfsvy$variables |> 
  group_by(msni) |> 
  count()) |> 
  ggplot(aes(x = msni, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x = "MSNI", y = "Average travel time to the nearest hospital (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = msni, y = 150, fill = NULL)) + 
  theme_bw()
```

##### rs_healthcare_accessibility2019

Correlacion de 20.35%. - Esto estaria mostrando cosas similares a Oxford access indicators + Las zonas rurales del país tienen condiciones más dificiles?

```{r}

dfsvy |> 
  group_by(msni) |> 
  summarise(
    distance_mean = survey_mean(rs_healthcare_accessibility2019,na.rm=T,"ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
  group_by(msni) |> 
  count()
  ) |> 
  ggplot(aes(x=msni,y=distance_mean,group=1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin= `distance_mean_low`,
        ymax= `distance_mean_upp`), 
                width=0.2)+
  labs(x= "MSNI", y = "Average travel time to the nearest hospital (min)")+
  geom_point()+
  geom_text(
            aes(label=n,x=msni,y=30, fill=NULL)) + 
  theme_bw()
```

##  {.unnumbered}

### OCHA

Se encontraron correlaciones entre algunos LSG y MSNI con las variables de RS como:

## Proteccion {.tabset .tabset-fade .tabset-pills}

la variable lsg_score_pro tuvo correlaciones mayores del 20% con las variables de remote sensing rs_NDVI_May2022, rs_NDVI_Mar2022, rs_city_accessibility2015 y rs_NDVI_Apr2022

### rs_NDVI_May2022

Correlacion de 25.30%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_pro) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_pro) |> 
  summarise(
    distance_mean = survey_mean(rs_NDVI_May2022, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_pro) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_pro) |> 
      count()
  ) |> 
  ggplot(aes(x = lsg_score_pro, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "Protection" , y = "Average NDVI may")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_pro, y = 1, fill = NULL)) + 
  theme_bw()
```

### rs_NDVI_Mar2022

Correlacion de 23.65%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_pro) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_pro) |> 
  summarise(
    distance_mean = survey_mean(rs_NDVI_Mar2022, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_pro) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_pro) |> 
      count()
  ) |> 
  ggplot(aes(x = lsg_score_pro, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "Protection" , y = "Average NDVI Mar")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_pro, y = 0.8, fill = NULL)) + 
  theme_bw()
```

### rs_city_accessibility2015

Correlacion de 22.80%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_pro) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_pro) |> 
  summarise(
    distance_mean = survey_mean(rs_city_accessibility2015, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_pro) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_pro) |> 
      count()
  ) |> 
  ggplot(aes(x = lsg_score_pro, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "Protection" , y = "Average travel time (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_pro, y = 100, fill = NULL)) + 
  theme_bw()
```

### rs_NDVI_Apr2022

Correlacion de 22.17%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_pro) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_pro) |> 
  summarise(
    distance_mean = survey_mean(rs_NDVI_Apr2022, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_pro) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_pro) |> 
      count()
  ) |> 
  ggplot(aes(x = lsg_score_pro, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "Protection" , y = "Average NDVI Apr")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_pro, y = 100, fill = NULL)) + 
  theme_bw()
```

##  {.unnumbered}

## WASH {.tabset .tabset-fade .tabset-pills}

la variable lsg_score_wash tuvo correlaciones mayores del 20% con las variables de remote sensing rs_healthcare_accessbility_walking_only2019, rs_NDVI_May2022, rs_city_accessibility2015 y rs_NDVI_Apr2022

### rs_healthcare_accessbility_walking_only2019

Correlacion de 36.53%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_wash) |> 
  summarise(
    distance_mean = survey_mean(rs_healthcare_accessbility_walking_only2019, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_wash) |> 
      count()
  ) |> 
  ggplot(aes(x=lsg_score_wash,y=distance_mean,group=1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH" , y = "Average travel time to the nearest hospital (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 250, fill = NULL)) + 
  theme_bw()
```

### rs_healthcare_accessibility2019

Correlacion de 30.22%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_wash) |> 
  summarise(
    distance_mean = survey_mean(rs_healthcare_accessibility2019, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_wash) |> 
      count()
  ) |> 
  ggplot(aes(x=lsg_score_wash,y=distance_mean,group=1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH" , y = "Average travel time to the nearest hospital (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 50, fill = NULL)) + 
  theme_bw()
```

### rs_NDVI_May2022

Correlacion de 30.04%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_wash) |> 
  summarise(
    distance_mean = survey_mean(rs_NDVI_May2022, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_wash) |> 
      count()
  ) |> 
  ggplot(aes(x=lsg_score_wash,y=distance_mean,group=1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH" , y = "Average NDVI May")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 0.8, fill = NULL)) + 
  theme_bw()
```

### rs_city_accessibility2015

Los LSG de WASH con la variable de rs_city_accessibility2015 tendrian una correlacion positiva a mayor distancia mas alto el LSG, aunque en los niveles más altos(4, 5) los intervalos de confianza tambien son grandes. Correlacion de 24.31%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_wash) |> 
  summarise(
    distance_mean = survey_mean(rs_city_accessibility2015, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_wash) |> 
      count()
  ) |> 
  ggplot(aes(x = lsg_score_wash, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH" , y = "Average travel time (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 125, fill = NULL)) + 
  theme_bw()
```

### rs_NDVI_Apr2022

Correlacion de 21.79%.

```{r}
dfsvy |> 
  filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(lsg_score_wash) |> 
  summarise(
    distance_mean = survey_mean(rs_NDVI_Apr2022, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(lsg_score_wash) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(lsg_score_wash) |> 
      count()
  ) |> 
  ggplot(aes(x = lsg_score_wash, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "WASH" , y = "Average NDVI Apr")+
  geom_point()+
  geom_text(
            aes(label = n, x = lsg_score_wash, y = 0.7, fill = NULL)) + 
  theme_bw()
```

##  {.unnumbered}

## MSNI {.tabset .tabset-fade .tabset-pills}

la variable msni tuvo correlaciones mayores del 20% con las variables de remote sensing rs_healthcare_accessbility_walking_only2019, rs_NDVI_May2022, rs_healthcare_accessibility2019 y rs_city_accessibility2015.

### rs_healthcare_accessbility_walking_only2019

Correlacion de 29.35%.

```{r}
dfsvy |> 
  filter(!is.na(msni) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(msni) |> 
  summarise(
    distance_mean = survey_mean(rs_healthcare_accessbility_walking_only2019, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(msni) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(msni) |> 
      count()
  ) |> 
  ggplot(aes(x = msni, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "MSNI" , y = "Average travel time to the nearest hospital (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = msni, y = 200, fill = NULL)) + 
  theme_bw()
```

### rs_NDVI_May2022

Correlacion de 27.08%.

```{r}
dfsvy |> 
  filter(!is.na(msni) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(msni) |> 
  summarise(
    distance_mean = survey_mean(rs_NDVI_May2022, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(msni) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(msni) |> 
      count()
  ) |> 
  ggplot(aes(x = msni, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "MSNI" , y = "Average NDVI May")+
  geom_point()+
  geom_text(
            aes(label = n, x = msni, y = 0.7, fill = NULL)) + 
  theme_bw()
```

### rs_healthcare_accessibility2019

Correlacion de 25.02%.

```{r}
dfsvy |> 
  filter(!is.na(msni) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(msni) |> 
  summarise(
    distance_mean = survey_mean(rs_healthcare_accessibility2019, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(msni) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(msni) |> 
      count()
  ) |> 
  ggplot(aes(x = msni, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "MSNI" , y = "Average travel time to the nearest hospital (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = msni, y = 40, fill = NULL)) + 
  theme_bw()
```

### rs_city_accessibility2015

Correlacion de 23.95%.

```{r}
dfsvy |> 
  filter(!is.na(msni) & pop_group %in% c("población de acogida", "PDI"))|>
  group_by(msni) |> 
  summarise(
    distance_mean = survey_mean(rs_city_accessibility2015, na.rm = T, "ci")
    ) |>
  left_join(
    #get raw counts
    dfsvy$variables |> 
      filter(!is.na(msni) & pop_group %in% c("población de acogida", "PDI"))|>
      group_by(msni) |> 
      count()
  ) |> 
  ggplot(aes(x = msni, y = distance_mean, group = 1))+
  geom_line(color = "red")+
  geom_errorbar(
    aes(ymin = `distance_mean_low`,
        ymax = `distance_mean_upp`), 
                width = 0.2)+
  labs(x= "MSNI" , y = "Average travel time (min)")+
  geom_point()+
  geom_text(
            aes(label = n, x = msni, y = 40, fill = NULL)) + 
  theme_bw()
```

##  {.unnumbered}

### GIFMM

Para GIFMM no hay sectores que tengan una correlacion mayor al 20% con las variables de RS. Cuando se mira las correlaciones sin los pesos si hay algunos sectores que tienen relaciones con la variables de RS como:

| rs_variables                  |  lsg_score_wash (%) |
|-------------------------------|---------------------|
| rs_May_spi9                   | 26.3819             |
| rs_May_spi6                   | 25.4479             |
| rs_May_spi12                  | 22.4524             |
| rs_col_climate_risk.riesgo_cc | 22.2031             |
| rs_col_climate_risk.vn_vs_am  | 22.1568             |


: Mejores correlaciones sin pesos para lsg_score_wash
